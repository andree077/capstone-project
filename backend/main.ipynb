{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import subprocess\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"C:/Projects/capstone-project/backend/global_emotion_model.h5\")\n",
    "audio_directory = \"C:/Projects/capstone-project/backend/uploads\"\n",
    "\n",
    "\n",
    "features_list = []\n",
    "for filename in os.listdir(audio_directory):\n",
    "    if filename.endswith(('.wav', '.mp3', '.flac', '.ogg')):\n",
    "        # load the audio file\n",
    "        audio_file, sr = librosa.load(os.path.join(audio_directory, filename), sr=None)\n",
    "\n",
    "        # extract the features\n",
    "        mfccs = librosa.feature.mfcc(y=audio_file, sr=sr, n_mfcc=30)\n",
    "        chroma = librosa.feature.chroma_stft(y=audio_file, sr=sr, n_chroma=20)\n",
    "\n",
    "        # concatenate the features into a single feature vector\n",
    "        features = np.concatenate((mfccs.mean(axis=1), mfccs.var(axis=1), chroma.mean(axis=1)))\n",
    "\n",
    "        features_list.append(features)\n",
    "        if not os.path.exists(\"C:/Projects/capstone-project/backend/acoustic_features\"):\n",
    "            os.mkdir(\"C:/Projects/capstone-project/backend/acoustic_features\")\n",
    "\n",
    "        acoustic_features_path = \"C:/Projects/capstone-project/backend/acoustic_features\"\n",
    "\n",
    "\n",
    "        csv_path = os.path.join(acoustic_features_path, f\"{filename}.csv\")\n",
    "        np.savetxt(csv_path, features, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = 'C:/Projects/capstone-project/backend/uploads'\n",
    "output_directory = 'C:/Projects/capstone-project/backend/transcriptions'\n",
    "linguistic_features_path = \"C:/Projects/capstone-project/backend/linguistic_features\"\n",
    "\n",
    "\n",
    "\n",
    "word2vec_model = Word2Vec.load(\"C:/Projects/capstone-project/backend/word2vec/model.model\")\n",
    "\n",
    "def get_word2vec_vectors(text, model):\n",
    "    tokens = word_tokenize(text)\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv.key_to_index]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    return np.zeros(model.vector_size)\n",
    "\n",
    "# Iterate through transcript directories\n",
    "\n",
    "for filename in os.listdir(output_directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            # Initialize lists to store features and emotions for each segment\n",
    "            linguistic_features = []\n",
    "            # Read the transcript\n",
    "            transcript_path = os.path.join(output_directory, filename)\n",
    "            with open(transcript_path, 'r') as file:\n",
    "                transcript_text = file.read()\n",
    "\n",
    "            # Get Word2Vec vectors\n",
    "            word2vec_vector = get_word2vec_vectors(transcript_text, word2vec_model)\n",
    "\n",
    "            # Extract emotion from the corresponding acoustic features CSV\n",
    "            acoustic_csv_path = os.path.join(acoustic_features_path, filename.replace(\".txt\", \".mp3.csv\"))\n",
    "            if os.path.exists(acoustic_csv_path):\n",
    "                acoustic_df = pd.read_csv(acoustic_csv_path)\n",
    "                emotion_label = acoustic_df.iloc[1, 1]  # Assuming emotion is in the second column after the second row\n",
    "            else:\n",
    "                emotion_label = \"Unknown\"  # Handle missing emotion label\n",
    "\n",
    "            # Append features and emotions to lists\n",
    "            for feature in word2vec_vector:\n",
    "                linguistic_features.append(feature)\n",
    "                emotions.append(emotion_label)\n",
    "\n",
    "            # Create a DataFrame for linguistic features and emotions\n",
    "            linguistic_df = pd.DataFrame({\n",
    "                \"Feature\": linguistic_features\n",
    "            })\n",
    "\n",
    "            # Save the DataFrame to a CSV file in the linguistic features directory\n",
    "            directory = os.path.join(linguistic_features_path)\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "            output_csv_path = os.path.join(directory, f\"{filename.replace('.txt', '.csv')}\")\n",
    "            linguistic_df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_directory = \"C:/Projects/capstone-project/backend/combined-features\"\n",
    "if not os.path.exists(combined_features_directory):\n",
    "  os.makedirs(combined_features_directory)\n",
    "\n",
    "# Loop through the acoustic features files\n",
    "for acoustic_file in os.listdir(acoustic_features_path):\n",
    "  # Get the segment file name\n",
    "  segment_file_name = acoustic_file.split(\".\")[0]\n",
    "  # Find the corresponding linguistic features file\n",
    "  linguistic_file = segment_file_name + \".csv\"\n",
    "  # Read the acoustic and linguistic features dataframes\n",
    "  acoustic_df = pd.read_csv(os.path.join(acoustic_features_path, acoustic_file))\n",
    "  linguistic_df = pd.read_csv(os.path.join(linguistic_features_path, linguistic_file))\n",
    "  # Rename the first column of the acoustic dataframe to \"Feature\"\n",
    "  acoustic_df.rename(columns={acoustic_df.columns[0]: \"Feature\"}, inplace=True)\n",
    "  # Remove the header row from the linguistic dataframe\n",
    "  linguistic_df = linguistic_df.iloc[1:]\n",
    "  # Rename the columns of the linguistic dataframe to match the acoustic dataframe\n",
    "  linguistic_df.columns = acoustic_df.columns\n",
    "  # Append the linguistic features to the acoustic features by rows\n",
    "  combined_df = pd.concat([acoustic_df, linguistic_df], axis=0)\n",
    "  # Save the combined dataframe to a new file\n",
    "  combined_file = segment_file_name + \".csv\"\n",
    "  combined_df.to_csv(os.path.join(combined_features_directory, combined_file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 1s 932ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "emotion_mapping = {\n",
    "    0: \"Happy\",\n",
    "    1: \"Sad\",\n",
    "    2: \"Confused\",\n",
    "    3: \"Other\"  # Add more emotions if needed\n",
    "}\n",
    "\n",
    "\n",
    "# Load the saved global model\n",
    "loaded_model = tf.keras.models.load_model(\"C:/Projects/capstone-project/backend/global_emotion_model.h5\")\n",
    "\n",
    "\n",
    "\n",
    "combined_features_directory = \"C:/Projects/capstone-project/backend/combined-features\"\n",
    "\n",
    "feature_files = [os.path.join(combined_features_directory, file) for file in os.listdir(combined_features_directory) if file.endswith(\".csv\")]\n",
    "\n",
    "emotions = []\n",
    "\n",
    "for feature_file in feature_files:\n",
    "    # Read the CSV file using Pandas\n",
    "    df = pd.read_csv(feature_file, header=None)\n",
    "\n",
    "    # Extract features (excluding the first row)\n",
    "    features = df.iloc[1:, 0].astype(np.float32).values\n",
    "\n",
    "    # Perform additional preprocessing if needed\n",
    "\n",
    "    # Predict the emotion using the loaded model\n",
    "    predicted_emotion = loaded_model.predict(features.reshape(1, -1))  # Reshape to match model input shape\n",
    "\n",
    "    predicted_emotion_label = emotion_mapping[np.argmax(predicted_emotion)]\n",
    "    # Map the predicted output to an emotion label (e.g., \"happy,\" \"sad,\" \"confused\")\n",
    "\n",
    "    # Append the emotion to the list of emotions\n",
    "    emotions.append(predicted_emotion_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Confused', 'Confused', 'Confused']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
